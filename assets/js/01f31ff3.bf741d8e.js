"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[88386],{66489:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>r,default:()=>g,frontMatter:()=>i,metadata:()=>s,toc:()=>c});var o=t(85893),a=t(11151);const i={title:"Integrating Foundation Models and Symbolic Computing for Next-Generation Robot Planning - Nov 18, 2024"},r=void 0,s={permalink:"/ag2/talks/2024/11/18/index",source:"@site/talks/2024-11-18/index.mdx",title:"Integrating Foundation Models and Symbolic Computing for Next-Generation Robot Planning - Nov 18, 2024",description:"Speakers: Yongchao Chen",date:"2024-11-18T00:00:00.000Z",formattedDate:"November 18, 2024",tags:[],readingTime:1.005,hasTruncateMarker:!1,authors:[],frontMatter:{title:"Integrating Foundation Models and Symbolic Computing for Next-Generation Robot Planning - Nov 18, 2024"},unlisted:!1,prevItem:{title:"Investigating Group Decision-Making Mechanism in Decentralized Multi-Agent Collaboration - Nov 25, 2024",permalink:"/ag2/talks/2024/11/25/index"},nextItem:{title:"Introducing FastAgency - the fastest way to bring AutoGen workflows to production - Nov 12, 2024",permalink:"/ag2/talks/2024/11/12/index"}},l={authorsImageUrls:[]},c=[{value:"Speakers: Yongchao Chen",id:"speakers-yongchao-chen",level:3},{value:"Biography of the speakers:",id:"biography-of-the-speakers",level:3},{value:"Abstract:",id:"abstract",level:3}];function d(e){const n={h3:"h3",p:"p",...(0,a.a)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.h3,{id:"speakers-yongchao-chen",children:"Speakers: Yongchao Chen"}),"\n",(0,o.jsx)(n.h3,{id:"biography-of-the-speakers",children:"Biography of the speakers:"}),"\n",(0,o.jsx)(n.p,{children:"Yongchao Chen is a PhD student of Electrical Engineering at Harvard SEAS and MIT LIDS. He is currently working on Robot Planning with Foundation Models under the guidance of Prof. Chuchu Fan and Prof. Nicholas Roy at MIT and co-advised by Prof. Na Li at Harvard. He is also doing the research in AI for Physics and Materials, particularly interested in applying Robotics/Foundation Models into AI4Science. Yongchao interned at Microsoft Research in 2024 summer and has been working with MIT-IBM Watson AI Lab starting from 2023 Spring."}),"\n",(0,o.jsx)(n.h3,{id:"abstract",children:"Abstract:"}),"\n",(0,o.jsx)(n.p,{children:"State-of-the-art language models, like GPT-4o and O1, continue to face challenges in solving tasks with intricate constraints involving logic, geometry, iteration, and optimization. While it's common to query LLMs to generate a plan purely through text output, we stress the importance of integrating symbolic computing to enhance general planning capabilities. By combining LLMs with symbolic planners and solvers, or guiding LLMs to generate code for planning, we enable them to address complex decision-making tasks for both real and virtual robots. This approach extends to various applications, including task and motion planning for drones and manipulators, travel itinerary planning, website agent design, and more."})]})}function g(e={}){const{wrapper:n}={...(0,a.a)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(d,{...e})}):d(e)}},11151:(e,n,t)=>{t.d(n,{Z:()=>s,a:()=>r});var o=t(67294);const a={},i=o.createContext(a);function r(e){const n=o.useContext(i);return o.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function s(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:r(e.components),o.createElement(i.Provider,{value:n},e.children)}}}]);