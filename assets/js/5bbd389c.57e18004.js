"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[63677],{59454:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>s,contentTitle:()=>o,default:()=>m,frontMatter:()=>r,metadata:()=>c,toc:()=>l});var a=n(74848),i=n(28453);const r={sidebar_label:"image_qa",title:"agentchat.contrib.captainagent.tools.information_retrieval.image_qa"},o=void 0,c={id:"reference/agentchat/contrib/captainagent/tools/information_retrieval/image_qa",title:"agentchat.contrib.captainagent.tools.information_retrieval.image_qa",description:"image\\_qa",source:"@site/docs/reference/agentchat/contrib/captainagent/tools/information_retrieval/image_qa.md",sourceDirName:"reference/agentchat/contrib/captainagent/tools/information_retrieval",slug:"/reference/agentchat/contrib/captainagent/tools/information_retrieval/image_qa",permalink:"/ag2/docs/reference/agentchat/contrib/captainagent/tools/information_retrieval/image_qa",draft:!1,unlisted:!1,editUrl:"https://github.com/ag2ai/ag2/edit/main/website/docs/reference/agentchat/contrib/captainagent/tools/information_retrieval/image_qa.md",tags:[],version:"current",frontMatter:{sidebar_label:"image_qa",title:"agentchat.contrib.captainagent.tools.information_retrieval.image_qa"},sidebar:"referenceSideBar",previous:{title:"get_youtube_caption",permalink:"/ag2/docs/reference/agentchat/contrib/captainagent/tools/information_retrieval/get_youtube_caption"},next:{title:"optical_character_recognition",permalink:"/ag2/docs/reference/agentchat/contrib/captainagent/tools/information_retrieval/optical_character_recognition"}},s={},l=[{value:"image_qa",id:"image_qa",level:3}];function g(e){const t={code:"code",em:"em",h3:"h3",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(t.h3,{id:"image_qa",children:"image_qa"}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-python",children:'@with_requirements(["transformers", "torch"],\n                   ["transformers", "torch", "PIL", "os"])\ndef image_qa(image, question, ckpt="Salesforce/blip-vqa-base")\n'})}),"\n",(0,a.jsx)(t.p,{children:"Perform question answering on an image using a pre-trained VQA model."}),"\n",(0,a.jsxs)(t.p,{children:[(0,a.jsx)(t.strong,{children:"Arguments"}),":"]}),"\n",(0,a.jsxs)(t.ul,{children:["\n",(0,a.jsxs)(t.li,{children:[(0,a.jsx)(t.code,{children:"image"})," ",(0,a.jsx)(t.em,{children:"Union[str, Image.Image]"})," - The image to perform question answering on. It can be either file path to the image or a PIL Image object."]}),"\n",(0,a.jsxs)(t.li,{children:[(0,a.jsx)(t.code,{children:"question"})," - The question to ask about the image."]}),"\n"]}),"\n",(0,a.jsxs)(t.p,{children:[(0,a.jsx)(t.strong,{children:"Returns"}),":"]}),"\n",(0,a.jsxs)(t.ul,{children:["\n",(0,a.jsxs)(t.li,{children:[(0,a.jsx)(t.code,{children:"dict"})," - The generated answer text."]}),"\n"]})]})}function m(e={}){const{wrapper:t}={...(0,i.R)(),...e.components};return t?(0,a.jsx)(t,{...e,children:(0,a.jsx)(g,{...e})}):g(e)}},28453:(e,t,n)=>{n.d(t,{R:()=>o,x:()=>c});var a=n(96540);const i={},r=a.createContext(i);function o(e){const t=a.useContext(r);return a.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function c(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:o(e.components),a.createElement(r.Provider,{value:t},e.children)}}}]);